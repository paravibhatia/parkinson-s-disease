# -*- coding: utf-8 -*-
"""parkinsons.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UJ8vAIvd53x6M82eagJdG6l7n2epziYV
"""

# importing necessary libraries and frameworks
import numpy as np
import pandas as pd
import os, sys
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler

from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

# reading csv file and printing its first five rows using head() function
df = pd.read_csv("Parkinsson diseasefinal.csv")
df.head()

# printing last five rows using tail() function
df.tail()

# printing dataset structural information
df.info()

# checking for duplicate values
df.duplicated().sum()

# performing statistical analysis
df.describe()

# calculating mean values with respect to each label
df.groupby('status').mean(numeric_only=True)

# separating feature columns and label columns
features=df.loc[:,df.columns!='status'].values[:,1:]
labels=df.loc[:,'status'].values
print(features)

# Geting the count of each label (0 and 1) in labels
df['status'].value_counts()

"""1-------> Parkinsons positive
0-------> healthy
that means we have 147 people who are parkinson's positive and 47 people negative
"""

# performing MinMaxScaling
from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler((-1,1))
x=scaler.fit_transform(features)
y=labels

# Spliting the dataset into training and testing samples
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x, y, test_size=0.2, random_state=50)

# initializing XGBClassifier and fitting it to our training feature columns and label columns
model=XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None, colsample_bylevel=1,
              colsample_bynode=1, colsample_bytree=1, gamma=0,
              learning_rate=0.1, max_delta_step=0, max_depth=3,
              min_child_weight=1, n_estimators=100, n_jobs=1,
              nthread=None, objective='binary:logistic', random_state=0,
              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
              silent=None, subsample=1, verbosity=1)
model.fit(x_train,y_train)

# Calculating accuracy(tp+tn/tp+tn+fp+fn)
y_pred=model.predict(x_test)
print(accuracy_score(y_test, y_pred))

# Calculating precision, recall, F1-Score and generating classification report


# precision=(tp/tp+fp)

# recall=(tp/tp+fn) ideally 1

from sklearn.metrics import precision_score, recall_score, f1_score

precision = precision_score(y_test, y_pred)

recall = recall_score(y_test, y_pred)

f1 = f1_score(y_test, y_pred)

print("Precision:", precision)
print("Recall:", recall)
print("F1-Score:", f1)

# plotting confusion matrix
cm=confusion_matrix(y_test,y_pred)
plt.figure(figsize=(8,6))
fg=sns.heatmap(cm,annot=True,cmap="Reds")
figure=fg.get_figure()
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title("Output Confusion Matrix")

